{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuizCarls/ML_Modelo_Cance_de_Mama/blob/main/ML_Modelo_Cance_de_Mama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otEdveLq8Hn0"
      },
      "source": [
        "## Autor - Luiz Carlos Sousa da Silva\n",
        "#### Este projeto compara e avalia diferentes modelos de classificação para prever se uma amostra de células é maligna ou benigna com base em características específicas extraídas do conjunto de dados de câncer de mama. O objetivo é identificar o modelo mais eficiente e preciso para auxiliar na detecção de câncer, utilizando métodos de aprendizado de máquina."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuração do ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RCn8CH4M7wF-"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pickle\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PcB0Efd-MS4"
      },
      "source": [
        "## Carga do Dataset\n",
        "\n",
        "O dataset contém informações sobre vários pacientes, com cada registro representando uma pessoa. As variáveis incluem características médicas relacionadas a medidas de células tumorais e outras informações sobre a morfologia do tumor. A última coluna, target (ou Outcome), indica se o tumor é maligno (1) ou benigno (0).\n",
        "\n",
        "Descrição de Cada Coluna\n",
        "- Mean area: A média das áreas das células no tumor, calculada a partir das áreas individuais das células. Isso ajuda a identificar o tamanho geral das células no tumor.\n",
        "- Mean perimeter: A média dos perímetros das células no tumor. O perímetro refere-se à medida ao redor da célula. Isso ajuda a descrever a forma e o tamanho das células.\n",
        "- Mean texture: A média da variação nos valores de textura das células no tumor. A textura descreve a variação nas intensidades da superfície celular, dando uma noção de quão \"irregular\" a célula pode ser.\n",
        "- Mean radius: A média dos raios das células no tumor. O raio é metade do diâmetro da célula, fornecendo uma ideia aproximada do tamanho das células.\n",
        "\n",
        "O objetivo é prever se um paciente possui um tumor maligno ou benigno com base em suas características médicas relacionadas à morfologia celular e outras medidas do tumor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "29AFuCPtvG_i",
        "outputId": "34ef3b38-211c-48a9-e153-1d2a8988f4c2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>12.45</td>\n",
              "      <td>15.70</td>\n",
              "      <td>82.57</td>\n",
              "      <td>477.1</td>\n",
              "      <td>0.12780</td>\n",
              "      <td>0.17000</td>\n",
              "      <td>0.15780</td>\n",
              "      <td>0.08089</td>\n",
              "      <td>0.2087</td>\n",
              "      <td>0.07613</td>\n",
              "      <td>...</td>\n",
              "      <td>15.47</td>\n",
              "      <td>23.75</td>\n",
              "      <td>103.40</td>\n",
              "      <td>741.6</td>\n",
              "      <td>0.1791</td>\n",
              "      <td>0.5249</td>\n",
              "      <td>0.5355</td>\n",
              "      <td>0.1741</td>\n",
              "      <td>0.3985</td>\n",
              "      <td>0.12440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>18.25</td>\n",
              "      <td>19.98</td>\n",
              "      <td>119.60</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>0.09463</td>\n",
              "      <td>0.10900</td>\n",
              "      <td>0.11270</td>\n",
              "      <td>0.07400</td>\n",
              "      <td>0.1794</td>\n",
              "      <td>0.05742</td>\n",
              "      <td>...</td>\n",
              "      <td>22.88</td>\n",
              "      <td>27.66</td>\n",
              "      <td>153.20</td>\n",
              "      <td>1606.0</td>\n",
              "      <td>0.1442</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.3784</td>\n",
              "      <td>0.1932</td>\n",
              "      <td>0.3063</td>\n",
              "      <td>0.08368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>13.71</td>\n",
              "      <td>20.83</td>\n",
              "      <td>90.20</td>\n",
              "      <td>577.9</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0.16450</td>\n",
              "      <td>0.09366</td>\n",
              "      <td>0.05985</td>\n",
              "      <td>0.2196</td>\n",
              "      <td>0.07451</td>\n",
              "      <td>...</td>\n",
              "      <td>17.06</td>\n",
              "      <td>28.14</td>\n",
              "      <td>110.60</td>\n",
              "      <td>897.0</td>\n",
              "      <td>0.1654</td>\n",
              "      <td>0.3682</td>\n",
              "      <td>0.2678</td>\n",
              "      <td>0.1556</td>\n",
              "      <td>0.3196</td>\n",
              "      <td>0.11510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>13.00</td>\n",
              "      <td>21.82</td>\n",
              "      <td>87.50</td>\n",
              "      <td>519.8</td>\n",
              "      <td>0.12730</td>\n",
              "      <td>0.19320</td>\n",
              "      <td>0.18590</td>\n",
              "      <td>0.09353</td>\n",
              "      <td>0.2350</td>\n",
              "      <td>0.07389</td>\n",
              "      <td>...</td>\n",
              "      <td>15.49</td>\n",
              "      <td>30.73</td>\n",
              "      <td>106.20</td>\n",
              "      <td>739.3</td>\n",
              "      <td>0.1703</td>\n",
              "      <td>0.5401</td>\n",
              "      <td>0.5390</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.4378</td>\n",
              "      <td>0.10720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>12.46</td>\n",
              "      <td>24.04</td>\n",
              "      <td>83.97</td>\n",
              "      <td>475.9</td>\n",
              "      <td>0.11860</td>\n",
              "      <td>0.23960</td>\n",
              "      <td>0.22730</td>\n",
              "      <td>0.08543</td>\n",
              "      <td>0.2030</td>\n",
              "      <td>0.08243</td>\n",
              "      <td>...</td>\n",
              "      <td>15.09</td>\n",
              "      <td>40.68</td>\n",
              "      <td>97.65</td>\n",
              "      <td>711.4</td>\n",
              "      <td>0.1853</td>\n",
              "      <td>1.0580</td>\n",
              "      <td>1.1050</td>\n",
              "      <td>0.2210</td>\n",
              "      <td>0.4366</td>\n",
              "      <td>0.20750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0        17.99         10.38          122.80     1001.0          0.11840   \n",
              "1        20.57         17.77          132.90     1326.0          0.08474   \n",
              "2        19.69         21.25          130.00     1203.0          0.10960   \n",
              "3        11.42         20.38           77.58      386.1          0.14250   \n",
              "4        20.29         14.34          135.10     1297.0          0.10030   \n",
              "5        12.45         15.70           82.57      477.1          0.12780   \n",
              "6        18.25         19.98          119.60     1040.0          0.09463   \n",
              "7        13.71         20.83           90.20      577.9          0.11890   \n",
              "8        13.00         21.82           87.50      519.8          0.12730   \n",
              "9        12.46         24.04           83.97      475.9          0.11860   \n",
              "\n",
              "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0           0.27760         0.30010              0.14710         0.2419   \n",
              "1           0.07864         0.08690              0.07017         0.1812   \n",
              "2           0.15990         0.19740              0.12790         0.2069   \n",
              "3           0.28390         0.24140              0.10520         0.2597   \n",
              "4           0.13280         0.19800              0.10430         0.1809   \n",
              "5           0.17000         0.15780              0.08089         0.2087   \n",
              "6           0.10900         0.11270              0.07400         0.1794   \n",
              "7           0.16450         0.09366              0.05985         0.2196   \n",
              "8           0.19320         0.18590              0.09353         0.2350   \n",
              "9           0.23960         0.22730              0.08543         0.2030   \n",
              "\n",
              "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
              "0                 0.07871  ...         25.38          17.33           184.60   \n",
              "1                 0.05667  ...         24.99          23.41           158.80   \n",
              "2                 0.05999  ...         23.57          25.53           152.50   \n",
              "3                 0.09744  ...         14.91          26.50            98.87   \n",
              "4                 0.05883  ...         22.54          16.67           152.20   \n",
              "5                 0.07613  ...         15.47          23.75           103.40   \n",
              "6                 0.05742  ...         22.88          27.66           153.20   \n",
              "7                 0.07451  ...         17.06          28.14           110.60   \n",
              "8                 0.07389  ...         15.49          30.73           106.20   \n",
              "9                 0.08243  ...         15.09          40.68            97.65   \n",
              "\n",
              "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
              "0      2019.0            0.1622             0.6656           0.7119   \n",
              "1      1956.0            0.1238             0.1866           0.2416   \n",
              "2      1709.0            0.1444             0.4245           0.4504   \n",
              "3       567.7            0.2098             0.8663           0.6869   \n",
              "4      1575.0            0.1374             0.2050           0.4000   \n",
              "5       741.6            0.1791             0.5249           0.5355   \n",
              "6      1606.0            0.1442             0.2576           0.3784   \n",
              "7       897.0            0.1654             0.3682           0.2678   \n",
              "8       739.3            0.1703             0.5401           0.5390   \n",
              "9       711.4            0.1853             1.0580           1.1050   \n",
              "\n",
              "   worst concave points  worst symmetry  worst fractal dimension  \n",
              "0                0.2654          0.4601                  0.11890  \n",
              "1                0.1860          0.2750                  0.08902  \n",
              "2                0.2430          0.3613                  0.08758  \n",
              "3                0.2575          0.6638                  0.17300  \n",
              "4                0.1625          0.2364                  0.07678  \n",
              "5                0.1741          0.3985                  0.12440  \n",
              "6                0.1932          0.3063                  0.08368  \n",
              "7                0.1556          0.3196                  0.11510  \n",
              "8                0.2060          0.4378                  0.10720  \n",
              "9                0.2210          0.4366                  0.20750  \n",
              "\n",
              "[10 rows x 30 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Carregando dataset de câncer de mama\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# Criar um DataFrame com as características e o alvo\n",
        "df = pd.DataFrame(data=data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "\n",
        "# Selecionar colunas específicas para o exemplo\n",
        "selected_columns = ['mean area', 'mean perimeter', 'mean texture', 'mean radius', 'target']\n",
        "df_selected = df[selected_columns]\n",
        "\n",
        "# Renomear a coluna 'target' para 'Diagnostic'\n",
        "df_selected.rename(columns={'target': 'Diagnostic'}, inplace=True)\n",
        "\n",
        "# Salvando o dataset ajustado\n",
        "df_selected.to_csv('./MachineLearning/data/test_dataset_cancers.csv', index=False)\n",
        "\n",
        "# Carregando dataset de câncer de mama\n",
        "dataset = pd.DataFrame(data=data.data, columns=data.feature_names)\n",
        "X = dataset[['mean area', 'mean perimeter', 'mean texture', 'mean radius']]  # Selecionando apenas os 4 atributos\n",
        "y = data.target\n",
        "\n",
        "# Mostra as primeiras linhas do dataset\n",
        "dataset.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 30 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   mean radius              569 non-null    float64\n",
            " 1   mean texture             569 non-null    float64\n",
            " 2   mean perimeter           569 non-null    float64\n",
            " 3   mean area                569 non-null    float64\n",
            " 4   mean smoothness          569 non-null    float64\n",
            " 5   mean compactness         569 non-null    float64\n",
            " 6   mean concavity           569 non-null    float64\n",
            " 7   mean concave points      569 non-null    float64\n",
            " 8   mean symmetry            569 non-null    float64\n",
            " 9   mean fractal dimension   569 non-null    float64\n",
            " 10  radius error             569 non-null    float64\n",
            " 11  texture error            569 non-null    float64\n",
            " 12  perimeter error          569 non-null    float64\n",
            " 13  area error               569 non-null    float64\n",
            " 14  smoothness error         569 non-null    float64\n",
            " 15  compactness error        569 non-null    float64\n",
            " 16  concavity error          569 non-null    float64\n",
            " 17  concave points error     569 non-null    float64\n",
            " 18  symmetry error           569 non-null    float64\n",
            " 19  fractal dimension error  569 non-null    float64\n",
            " 20  worst radius             569 non-null    float64\n",
            " 21  worst texture            569 non-null    float64\n",
            " 22  worst perimeter          569 non-null    float64\n",
            " 23  worst area               569 non-null    float64\n",
            " 24  worst smoothness         569 non-null    float64\n",
            " 25  worst compactness        569 non-null    float64\n",
            " 26  worst concavity          569 non-null    float64\n",
            " 27  worst concave points     569 non-null    float64\n",
            " 28  worst symmetry           569 non-null    float64\n",
            " 29  worst fractal dimension  569 non-null    float64\n",
            "dtypes: float64(30)\n",
            "memory usage: 133.5 KB\n"
          ]
        }
      ],
      "source": [
        "dataset.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE4-PIaTAfKX"
      },
      "source": [
        "## Separação em conjunto de treino e conjunto de teste com holdout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fEiAm3LEAfPt"
      },
      "outputs": [],
      "source": [
        "# Definindo o tamanho do conjunto de teste e a semente aleatória\n",
        "test_size = 0.20 # tamanho do conjunto de teste\n",
        "seed = 7 # semente aleatória\n",
        "\n",
        "# Separação em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size,\n",
        "                                  shuffle=True, random_state=seed, stratify=y)\n",
        "\n",
        "# Parâmetros e partições da validação cruzada\n",
        "scoring = 'accuracy'\n",
        "num_particoes = 10\n",
        "kfold = StratifiedKFold(n_splits=num_particoes, shuffle=True, random_state=seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2OGe0DtAfU4"
      },
      "source": [
        "## Modelagem e Inferência"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwHzQpbX9QQh"
      },
      "source": [
        "### Criação e avaliação de modelos: linha base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 854
        },
        "id": "eAhfSnnIAfke",
        "outputId": "e912a3ba-17ed-48e0-8ee2-f7be04f3d715"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR: 0.914106 (0.042707)\n",
            "KNN: 0.892174 (0.043597)\n",
            "CART: 0.874734 (0.040651)\n",
            "NB: 0.881063 (0.053852)\n",
            "SVM: 0.878937 (0.044788)\n",
            "Bagging: 0.892174 (0.042848)\n",
            "RF: 0.896570 (0.042330)\n",
            "ET: 0.898792 (0.042251)\n",
            "Ada: 0.890048 (0.054134)\n",
            "GB: 0.901063 (0.037446)\n",
            "Voting: 0.905314 (0.043226)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "np.random.seed(7) # Definindo uma semente global\n",
        "\n",
        "# Lista que armazenará os modelos\n",
        "models = []\n",
        "\n",
        "# Criando os modelos e adicionando-os na lista de modelos\n",
        "models.append(('LR', LogisticRegression(max_iter=200)))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('CART', DecisionTreeClassifier()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVM', SVC()))\n",
        "\n",
        "# Definindo os parâmetros do classificador base para o BaggingClassifier\n",
        "base = DecisionTreeClassifier()\n",
        "num_trees = 100\n",
        "max_features = 3\n",
        "\n",
        "# Criando os modelos para o VotingClassifier\n",
        "bases = []\n",
        "model1 = LogisticRegression(max_iter=200)\n",
        "bases.append(('logistic', model1))\n",
        "model2 = DecisionTreeClassifier()\n",
        "bases.append(('cart', model2))\n",
        "model3 = SVC()\n",
        "bases.append(('svm', model3))\n",
        "\n",
        "# Criando os ensembles e adicionando-os na lista de modelos\n",
        "models.append(('Bagging', BaggingClassifier(estimator=base, n_estimators=num_trees)))\n",
        "models.append(('RF', RandomForestClassifier(n_estimators=num_trees, max_features=max_features)))\n",
        "models.append(('ET', ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)))\n",
        "models.append(('Ada', AdaBoostClassifier(n_estimators=num_trees)))\n",
        "models.append(('GB', GradientBoostingClassifier(n_estimators=num_trees)))\n",
        "models.append(('Voting', VotingClassifier(estimators=bases)))\n",
        "\n",
        "# Listas para armazenar os resultados\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "# Avaliação dos modelos\n",
        "for name, model in models:\n",
        "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n",
        "\n",
        "# Boxplot de comparação dos modelos\n",
        "fig = plt.figure(figsize=(15,10))\n",
        "fig.suptitle('Comparação dos Modelos')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olo7SPk2BvvW"
      },
      "source": [
        "### Criação e avaliação de modelos: dados padronizados e normalizados\n",
        "\n",
        "Trabalhando com dados pontencialmente desbalanceados ou sensíveis a escala\n",
        "\n",
        "StandardScaler (padronização do conjunto de dados) e MinMaxScaler (normalização do conjunto de dados) são duas técnicas de normalização/escala usadas em machine learning para pré-processamento de dados e são úteis para preparar dados para algoritmos de aprendizado de máquina que são sensíveis à escala dos dados.\n",
        "\n",
        "##### StandardScaler\n",
        "StandardScaler padroniza os dados, ou seja, remove a média e escala os dados para que tenham uma variância unitária. Ele transforma os dados para que a média de cada feature seja 0 e a variância seja 1.\n",
        "\n",
        "Fórmula: $z_i=\\frac{x_i-\\mu}{\\sigma}$\n",
        "\n",
        " \n",
        "onde:\n",
        "- $x_i$ é o valor original do $i$-ésimo termo da feature.\n",
        "- $\\mu$ é a média dos valores da feature.\n",
        "- $\\sigma$ é o desvio padrão dos valores da feature.\n",
        "𝑥\n",
        "x é o valor original da feature.\n",
        "𝜇\n",
        "μ é a média dos valores da feature.\n",
        "𝜎\n",
        "σ é o desvio padrão dos valores da feature.\n",
        "\n",
        "\n",
        "##### MinMaxScaler\n",
        "MinMaxScaler escala e transforma os dados para um intervalo específico, geralmente entre 0 e 1. Ele transforma os dados para que o menor valor de uma feature seja 0 e o maior valor seja 1.\n",
        "\n",
        "Fórmula: $z_i=\\frac{x_i-min(x)}{max(x)-min(x)}$\n",
        "\n",
        "onde:\n",
        "- $x_i$ é o valor original do $i$-ésimo termo da feature.\n",
        "- $min(x)$ é o menor valor da feature.\n",
        "- $max(x)$ é o maior valor da feature.\n",
        "\n",
        "Nós vamos aplicar essas técnicas para os dados do dataset de diabetes através da construção de pipelines. Pipelines são uma maneira de simplificar o processo de construção de modelos, permitindo que você execute várias etapas de pré-processamento e modelagem em sequência."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hmQbiYQdBRDW",
        "outputId": "c0c16336-31ba-4dc3-937a-15e07f1d8de1"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "BaggingClassifier.__init__() got an unexpected keyword argument 'base_estimator'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m naive_bayes \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNB\u001b[39m\u001b[38;5;124m'\u001b[39m, GaussianNB())\n\u001b[0;32m     13\u001b[0m svm \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVM\u001b[39m\u001b[38;5;124m'\u001b[39m, SVC())\n\u001b[1;32m---> 14\u001b[0m bagging \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBag\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mBaggingClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_trees\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     15\u001b[0m random_forest \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRF\u001b[39m\u001b[38;5;124m'\u001b[39m, RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39mnum_trees, max_features\u001b[38;5;241m=\u001b[39mmax_features))\n\u001b[0;32m     16\u001b[0m extra_trees \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mET\u001b[39m\u001b[38;5;124m'\u001b[39m, ExtraTreesClassifier(n_estimators\u001b[38;5;241m=\u001b[39mnum_trees, max_features\u001b[38;5;241m=\u001b[39mmax_features))\n",
            "\u001b[1;31mTypeError\u001b[0m: BaggingClassifier.__init__() got an unexpected keyword argument 'base_estimator'"
          ]
        }
      ],
      "source": [
        "np.random.seed(7) # Definindo uma semente global para este bloco\n",
        "\n",
        "# Listas para armazenar os pipelines e os resultados para todas as visões do dataset\n",
        "pipelines = []\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "# Criando os elementos do pipeline\n",
        "reg_log = ('LR', LogisticRegression(max_iter=200))\n",
        "knn = ('KNN', KNeighborsClassifier())\n",
        "cart = ('CART', DecisionTreeClassifier())\n",
        "naive_bayes = ('NB', GaussianNB())\n",
        "svm = ('SVM', SVC())\n",
        "bagging = ('Bag', BaggingClassifier(base_estimator=base, n_estimators=num_trees))\n",
        "random_forest = ('RF', RandomForestClassifier(n_estimators=num_trees, max_features=max_features))\n",
        "extra_trees = ('ET', ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features))\n",
        "adaboost = ('Ada', AdaBoostClassifier(n_estimators=num_trees))\n",
        "gradient_boosting = ('GB', GradientBoostingClassifier(n_estimators=num_trees))\n",
        "voting = ('Voting', VotingClassifier(estimators=bases))\n",
        "\n",
        "# Transformações que serão utilizadas\n",
        "standard_scaler = ('StandardScaler', StandardScaler())\n",
        "min_max_scaler = ('MinMaxScaler', MinMaxScaler())\n",
        "\n",
        "# Montando os pipelines\n",
        "pipelines.append(('LR-orig', Pipeline([reg_log])))\n",
        "pipelines.append(('KNN-orig', Pipeline([knn])))\n",
        "pipelines.append(('CART-orig', Pipeline([cart])))\n",
        "pipelines.append(('NB-orig', Pipeline([naive_bayes])))\n",
        "pipelines.append(('SVM-orig', Pipeline([svm])))\n",
        "pipelines.append(('Bag-orig', Pipeline([bagging])))\n",
        "pipelines.append(('RF-orig', Pipeline([random_forest])))\n",
        "pipelines.append(('ET-orig', Pipeline([extra_trees])))\n",
        "pipelines.append(('Ada-orig', Pipeline([adaboost])))\n",
        "pipelines.append(('GB-orig', Pipeline([gradient_boosting])))\n",
        "pipelines.append(('Vot-orig', Pipeline([voting])))\n",
        "\n",
        "# Dataset Padronizado\n",
        "pipelines.append(('LR-padr', Pipeline([standard_scaler, reg_log])))\n",
        "pipelines.append(('KNN-padr', Pipeline([standard_scaler, knn])))\n",
        "pipelines.append(('CART-padr', Pipeline([standard_scaler, cart])))\n",
        "pipelines.append(('NB-padr', Pipeline([standard_scaler, naive_bayes])))\n",
        "pipelines.append(('SVM-padr', Pipeline([standard_scaler, svm])))\n",
        "pipelines.append(('Bag-padr', Pipeline([standard_scaler, bagging])))\n",
        "pipelines.append(('RF-padr', Pipeline([standard_scaler, random_forest])))\n",
        "pipelines.append(('ET-padr', Pipeline([standard_scaler, extra_trees])))\n",
        "pipelines.append(('Ada-padr', Pipeline([standard_scaler, adaboost])))\n",
        "pipelines.append(('GB-padr', Pipeline([standard_scaler, gradient_boosting])))\n",
        "pipelines.append(('Vot-padr', Pipeline([standard_scaler, voting])))\n",
        "\n",
        "# Dataset Normalizado\n",
        "pipelines.append(('LR-norm', Pipeline([min_max_scaler, reg_log])))\n",
        "pipelines.append(('KNN-norm', Pipeline([min_max_scaler, knn])))\n",
        "pipelines.append(('CART-norm', Pipeline([min_max_scaler, cart])))\n",
        "pipelines.append(('NB-norm', Pipeline([min_max_scaler, naive_bayes])))\n",
        "pipelines.append(('SVM-norm', Pipeline([min_max_scaler, svm])))\n",
        "pipelines.append(('Bag-norm', Pipeline([min_max_scaler, bagging])))\n",
        "pipelines.append(('RF-norm', Pipeline([min_max_scaler, random_forest])))\n",
        "pipelines.append(('ET-norm', Pipeline([min_max_scaler, extra_trees])))\n",
        "pipelines.append(('Ada-norm', Pipeline([min_max_scaler, adaboost])))\n",
        "pipelines.append(('GB-norm', Pipeline([min_max_scaler, gradient_boosting])))\n",
        "pipelines.append(('Vot-norm', Pipeline([min_max_scaler, voting])))\n",
        "\n",
        "# Executando os pipelines\n",
        "for name, model in pipelines:\n",
        "    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %.3f (%.3f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n",
        "\n",
        "# Boxplot de comparação dos pipelines\n",
        "fig = plt.figure(figsize=(25,6))\n",
        "fig.suptitle('Comparação dos Modelos - Dataset orginal, padronizado e normalizado') \n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names, rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-f2vCU5CMmp"
      },
      "source": [
        "### Otimização dos hiperparâmetros\n",
        "\n",
        "A otimização de hiperparâmetros é o processo de encontrar os valores ideais para os hiperparâmetros de um modelo de machine learning. O objetivo é encontrar a combinação de hiperparâmetros que resulta no melhor desempenho do modelo.\n",
        "\n",
        "\n",
        "##### Grid Search (*força bruta*)\n",
        "\n",
        "Como Funciona o Grid Search?\n",
        "1. Definição do Espaço de Hiperparâmetros: Primeiro, define-se um conjunto de valores possíveis para cada hiperparâmetro.\n",
        "2. Avaliação das Combinações: Em seguida, cada combinação possível desses valores é avaliada.\n",
        "3. Seleção do Melhor Conjunto: A combinação de hiperparâmetros que produz o melhor desempenho é selecionada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sem tratamento de missings: knn-orig - Melhor: 0.892174 usando {'KNN__metric': 'euclidean', 'KNN__n_neighbors': 5}\n",
            "Sem tratamento de missings: knn-padr - Melhor: 0.907633 usando {'KNN__metric': 'euclidean', 'KNN__n_neighbors': 3}\n",
            "Sem tratamento de missings: knn-norm - Melhor: 0.907536 usando {'KNN__metric': 'manhattan', 'KNN__n_neighbors': 3}\n"
          ]
        }
      ],
      "source": [
        "# Tuning do KNN\n",
        "np.random.seed(7) # Definindo uma semente global para este bloco\n",
        "\n",
        "pipelines = []\n",
        "\n",
        "# Definindo os componentes do pipeline\n",
        "knn = ('KNN', KNeighborsClassifier())\n",
        "standard_scaler = ('StandardScaler', StandardScaler())\n",
        "min_max_scaler = ('MinMaxScaler', MinMaxScaler())\n",
        "\n",
        "pipelines.append(('knn-orig', Pipeline(steps=[knn])))\n",
        "pipelines.append(('knn-padr', Pipeline(steps=[standard_scaler, knn])))\n",
        "pipelines.append(('knn-norm', Pipeline(steps=[min_max_scaler, knn])))\n",
        "\n",
        "param_grid = {\n",
        "    'KNN__n_neighbors': [3, 5, 7, 9],\n",
        "    'KNN__metric': [\"euclidean\", \"manhattan\", \"minkowski\"],\n",
        "}\n",
        "\n",
        "# Executando o tuning\n",
        "for name, model in pipelines:\n",
        "    grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
        "    grid.fit(X_train, y_train)\n",
        "    # imprime a melhor configuração\n",
        "    print(\"Sem tratamento de missings: %s - Melhor: %f usando %s\" % (name, grid.best_score_, grid.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modelo: LR-orig - Melhor: 0.766987 usando {'LR__C': 100, 'LR__solver': 'liblinear'}\n",
        "# Modelo: LR-padr - Melhor: 0.770239 usando {'LR__C': 1, 'LR__solver': 'liblinear'}\n",
        "# Modelo: LR-norm - Melhor: 0.768613 usando {'LR__C': 100, 'LR__solver': 'liblinear'}\n",
        "# Modelo: KNN-orig - Melhor: 0.758843 usando {'KNN__metric': 'euclidean', 'KNN__n_neighbors': 13}\n",
        "# Modelo: KNN-padr - Melhor: 0.752406 usando {'KNN__metric': 'euclidean', 'KNN__n_neighbors': 19}\n",
        "# Modelo: KNN-norm - Melhor: 0.752406 usando {'KNN__metric': 'manhattan', 'KNN__n_neighbors': 19}\n",
        "# Modelo: CART-orig - Melhor: 0.713275 usando {'CART__max_depth': 10, 'CART__min_samples_leaf': 2, 'CART__min_samples_split': 5}\n",
        "# Modelo: CART-padr - Melhor: 0.711649 usando {'CART__max_depth': 40, 'CART__min_samples_leaf': 2, 'CART__min_samples_split': 2}\n",
        "# Modelo: CART-norm - Melhor: 0.711715 usando {'CART__max_depth': 40, 'CART__min_samples_leaf': 4, 'CART__min_samples_split': 2}\n",
        "# Modelo: NB-orig - Melhor: 0.749114 usando {'NB__var_smoothing': 1e-08}\n",
        "# Modelo: NB-padr - Melhor: 0.747488 usando {'NB__var_smoothing': 1e-09}\n",
        "# Modelo: NB-norm - Melhor: 0.747488 usando {'NB__var_smoothing': 1e-09}\n",
        "# Modelo: SVM-orig - Melhor: 0.768653 usando {'SVM__C': 100, 'SVM__gamma': 1, 'SVM__kernel': 'linear'}\n",
        "# Modelo: SVM-padr - Melhor: 0.770279 usando {'SVM__C': 10, 'SVM__gamma': 0.01, 'SVM__kernel': 'rbf'}\n",
        "# Modelo: SVM-norm - Melhor: 0.775157 usando {'SVM__C': 100, 'SVM__gamma': 0.1, 'SVM__kernel': 'rbf'}\n",
        "# Modelo: Bagging-orig - Melhor: 0.757270 usando {}\n",
        "# Modelo: Bagging-padr - Melhor: 0.760549 usando {}\n",
        "# Modelo: Bagging-norm - Melhor: 0.755618 usando {}\n",
        "# Modelo: RF-orig - Melhor: 0.776796 usando {'RF__max_depth': 30, 'RF__max_features': 'sqrt', 'RF__min_samples_leaf': 2, 'RF__min_samples_split': 5, 'RF__n_estimators': 200}\n",
        "# Modelo: RF-padr - Melhor: 0.776823 usando {'RF__max_depth': None, 'RF__max_features': 'log2', 'RF__min_samples_leaf': 4, 'RF__min_samples_split': 10, 'RF__n_estimators': 50}\n",
        "# Modelo: RF-norm - Melhor: 0.783287 usando {'RF__max_depth': 10, 'RF__max_features': 'sqrt', 'RF__min_samples_leaf': 1, 'RF__min_samples_split': 2, 'RF__n_estimators': 50}\n",
        "# Modelo: ET-orig - Melhor: 0.781714 usando {'ET__max_depth': 10, 'ET__max_features': 'sqrt', 'ET__min_samples_leaf': 1, 'ET__min_samples_split': 5, 'ET__n_estimators': 50}\n",
        "# Modelo: ET-padr - Melhor: 0.776863 usando {'ET__max_depth': 10, 'ET__max_features': 'log2', 'ET__min_samples_leaf': 2, 'ET__min_samples_split': 5, 'ET__n_estimators': 100}\n",
        "# Modelo: ET-norm - Melhor: 0.776836 usando {'ET__max_depth': 30, 'ET__max_features': 'log2', 'ET__min_samples_leaf': 4, 'ET__min_samples_split': 10, 'ET__n_estimators': 100}\n",
        "# Modelo: Ada-orig - Melhor: 0.765414 usando {'Ada__learning_rate': 0.1, 'Ada__n_estimators': 100}\n",
        "# Modelo: Ada-padr - Melhor: 0.765414 usando {'Ada__learning_rate': 0.1, 'Ada__n_estimators': 100}\n",
        "# Modelo: Ada-norm - Melhor: 0.765414 usando {'Ada__learning_rate': 0.1, 'Ada__n_estimators': 100}\n",
        "# Modelo: GB-orig - Melhor: 0.762188 usando {'GB__learning_rate': 0.2, 'GB__max_depth': 7, 'GB__n_estimators': 100}\n",
        "# Modelo: GB-padr - Melhor: 0.763774 usando {'GB__learning_rate': 0.1, 'GB__max_depth': 5, 'GB__n_estimators': 200}\n",
        "# Modelo: GB-norm - Melhor: 0.767067 usando {'GB__learning_rate': 0.3, 'GB__max_depth': 9, 'GB__n_estimators': 100}\n",
        "# Modelo: Voting-orig - Melhor: 0.758896 usando {}\n",
        "# Modelo: Voting-padr - Melhor: 0.757217 usando {}\n",
        "# Modelo: Voting-norm - Melhor: 0.755631 usando {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBSDgpXNt1Fp",
        "outputId": "c54a1a17-099b-46b9-cef8-8622acce8379"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sem tratamento de missings: knn-orig - Melhor: 0.892174 usando {'KNN__metric': 'euclidean', 'KNN__n_neighbors': 5}\n",
            "Sem tratamento de missings: knn-padr - Melhor: 0.907633 usando {'KNN__metric': 'euclidean', 'KNN__n_neighbors': 3}\n",
            "Sem tratamento de missings: knn-norm - Melhor: 0.907536 usando {'KNN__metric': 'manhattan', 'KNN__n_neighbors': 3}\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(7) # Definindo uma semente global para este bloco\n",
        "\n",
        "pipelines = []\n",
        "\n",
        "# Definindo os componentes do pipeline\n",
        "knn = ('KNN', KNeighborsClassifier())\n",
        "standard_scaler = ('StandardScaler', StandardScaler())\n",
        "min_max_scaler = ('MinMaxScaler', MinMaxScaler())\n",
        "\n",
        "pipelines.append(('knn-orig', Pipeline(steps=[knn])))\n",
        "pipelines.append(('knn-padr', Pipeline(steps=[standard_scaler, knn])))\n",
        "pipelines.append(('knn-norm', Pipeline(steps=[min_max_scaler, knn])))\n",
        "\n",
        "param_grid = {\n",
        "    'KNN__n_neighbors': [3, 5, 7, 9],\n",
        "    'KNN__metric': [\"euclidean\", \"manhattan\", \"minkowski\"],\n",
        "}\n",
        "\n",
        "# Executando o tuning\n",
        "for name, model in pipelines:\n",
        "    grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\n",
        "    grid.fit(X_train, y_train)\n",
        "    # imprime a melhor configuração\n",
        "    print(\"Sem tratamento de missings: %s - Melhor: %f usando %s\" % (name, grid.best_score_, grid.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuUpaYcwDRDt"
      },
      "source": [
        "## Finalização do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbrFxAbSDVIj",
        "outputId": "9c539faf-590f-494f-bcf6-e8ab4fd8c5d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acurácia no conjunto de teste: 0.8859649122807017\n"
          ]
        }
      ],
      "source": [
        "# Avaliação do modelo com o conjunto de testes\n",
        "\n",
        "# Preparação do modelo\n",
        "scaler = StandardScaler().fit(X_train)  # ajuste do scaler com o conjunto de treino\n",
        "rescaledX = scaler.transform(X_train)  # aplicação da padronização no conjunto de treino\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(rescaledX, y_train)\n",
        "\n",
        "# Estimativa da acurácia no conjunto de teste\n",
        "rescaledTestX = scaler.transform(X_test)  # aplicação da padronização no conjunto de teste\n",
        "predictions = model.predict(rescaledTestX)\n",
        "print(\"Acurácia no conjunto de teste:\", accuracy_score(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Rodando o modelo a partir de um pipeline com os hiperparâmetros otimizados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9298245614035088\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(7)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=50, \n",
        "                               max_features='sqrt',\n",
        "                               min_samples_split=2,\n",
        "                               max_depth=10,\n",
        "                               min_samples_leaf=1)\n",
        "\n",
        "pipeline = Pipeline(steps=[('MinMaxScaler', MinMaxScaler()), ('RF', model)])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "predictions = pipeline.predict(X_test)\n",
        "print(accuracy_score(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Salvando os arquivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definindo nomes de arquivos\n",
        "model_filename = 'rf_cancer_mama_classifier.pkl'\n",
        "scaler_filename = 'minmax_scaler_cancers.pkl'\n",
        "pipeline_filename = 'rf_cancers_pipeline.pkl'\n",
        "X_test_filename = 'x_test_dataset_cancers.csv'\n",
        "y_test_filename = 'y_test_dataset_cancers.csv'\n",
        "\n",
        "# Salvando o modelo\n",
        "with open(\"../models/\" + model_filename, 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "\n",
        "# Salvando o scaler\n",
        "with open(\"../scalers/\" + scaler_filename, 'wb') as file:\n",
        "    pickle.dump(scaler, file)\n",
        "\n",
        "# Salvando o pipeline\n",
        "with open(\"../pipelines/\" + pipeline_filename, 'wb') as file:\n",
        "    pickle.dump(pipeline, file)\n",
        "\n",
        "# Salvando X_test e y_test\n",
        "X_test_df = pd.DataFrame(X_test, columns=dataset.columns[:-1])\n",
        "y_test_df = pd.DataFrame(y_test, columns=[dataset.columns[-1]])\n",
        "X_test_df.to_csv(\"../data/\" + X_test_filename, index=False)\n",
        "y_test_df.to_csv(\"../data/\" + y_test_filename, index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ-FQWZj_OtQ"
      },
      "source": [
        "## Simulando a aplicação do modelo em dados não vistos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGeQHmeg4ziu",
        "outputId": "b025bf90-0341-4108-9b72-0532296fce37"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, n_estimators=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=10, n_estimators=50)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(max_depth=10, n_estimators=50)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preparação do modelo com TODO o dataset\n",
        "scaler = StandardScaler().fit(X)  # ajuste do scaler com TODO o dataset\n",
        "rescaledX = scaler.transform(X)  # aplicação da padronização com TODO o dataset\n",
        "model.fit(rescaledX, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAIp6d9w5QG8",
        "outputId": "0dcf113e-145a-48dc-c582-e8118b16f68a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.4405205  -0.08110488  0.28165692 -0.03615266]\n",
            " [-0.29831537  0.33079712  0.63071699  0.38986863]\n",
            " [-0.49740256 -0.26646078  0.46782229 -0.12135692]]\n"
          ]
        }
      ],
      "source": [
        "# Ajustando os novos dados para ter os mesmos nomes de colunas que no treinamento\n",
        "data = {\n",
        "    'mean area': [500.0, 550.0, 480.0],\n",
        "    'mean perimeter': [90.0, 100.0, 85.5],\n",
        "    'mean texture': [20.5, 22.0, 21.3],\n",
        "    'mean radius': [14.0, 15.5, 13.7],\n",
        "}\n",
        "\n",
        "# Verificar as colunas utilizadas no treinamento\n",
        "atributos = ['mean area', 'mean perimeter', 'mean texture', 'mean radius']\n",
        "entrada = pd.DataFrame(data, columns=atributos)\n",
        "\n",
        "# Convertendo para DataFrame e garantindo a ordem correta das colunas\n",
        "df_novos_dados = pd.DataFrame(data)\n",
        "df_novos_dados = df_novos_dados[atributos]  # Reordenar as colunas para corresponder à ordem de treinamento\n",
        "\n",
        "array_entrada = entrada.values\n",
        "X_entrada = array_entrada[:,0:8].astype(float)\n",
        "\n",
        "# Padronização nos dados de entrada usando o scaler utilizado em X\n",
        "rescaledEntradaX = scaler.transform(X_entrada)\n",
        "print(rescaledEntradaX)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQf_VFWy5Qsm",
        "outputId": "3aab9b1d-65ad-4f00-abf8-48e3c9342a02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predições para os novos dados:  [1 0 1]\n"
          ]
        }
      ],
      "source": [
        "# Fazendo a predição com o melhor modelo\n",
        "saidas = model.predict(rescaledEntradaX)\n",
        "\n",
        "# Imprimindo resultados\n",
        "print(\"Predições para os novos dados: \", saidas)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "mE4-PIaTAfKX"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
